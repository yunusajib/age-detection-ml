{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81fdddbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "import pandas as pd\n",
    "from src.data.dataloader import make_dataset\n",
    "\n",
    "train_df = pd.read_csv(\"../data/processed/train.csv\")\n",
    "val_df   = pd.read_csv(\"../data/processed/val.csv\")\n",
    "test_df  = pd.read_csv(\"../data/processed/test.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b839b7",
   "metadata": {},
   "source": [
    "# Build Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "482e25bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'src.data.dataloader' from '/Users/yunusajib/Desktop/age-detection-ml/src/data/dataloader.py'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "import src.data.dataloader as dl\n",
    "\n",
    "reload(dl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47c1d8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = dl.load_split_csv(\"../data/processed/train.csv\")\n",
    "train_ds = dl.make_dataset(train_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b586d103",
   "metadata": {},
   "source": [
    "# Inspect one Batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a5c76317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def make_dataset(df, batch_size=32, shuffle=True):\n",
      "    pixel_strings = df[\"pixels\"].values\n",
      "    ages = df[\"age\"].values\n",
      "    ethnicity = df[\"ethnicity\"].values\n",
      "    genders = df[\"gender\"].values\n",
      "\n",
      "    dataset = tf.data.Dataset.from_tensor_slices(\n",
      "        (pixel_strings, ages, ethnicity, genders)\n",
      "    )\n",
      "\n",
      "    # Python-side processing\n",
      "    def _process(pixel_string, age, eth, gender):\n",
      "        img = load_image_from_pixels(pixel_string.numpy().decode(\"utf-8\"))\n",
      "        return (\n",
      "            img,\n",
      "            tf.cast(age, tf.float32),\n",
      "            tf.cast(eth, tf.int32),\n",
      "            tf.cast(gender, tf.int32),\n",
      "        )\n",
      "\n",
      "    # TensorFlow wrapper\n",
      "    def _tf_process(pixel_string, age, eth, gender):\n",
      "        img, age_out, eth_out, gender_out = tf.py_function(\n",
      "            func=_process,\n",
      "            inp=[pixel_string, age, eth, gender],\n",
      "            Tout=[tf.float32, tf.float32, tf.int32, tf.int32],\n",
      "        )\n",
      "\n",
      "        img.set_shape((48, 48, 3))\n",
      "        age_out.set_shape(())\n",
      "        eth_out.set_shape(())\n",
      "        gender_out.set_shape(())\n",
      "\n",
      "        labels = {\n",
      "            \"age\": age_out,\n",
      "            \"ethnicity\": eth_out,\n",
      "            \"gender\": gender_out,\n",
      "        }\n",
      "\n",
      "        return img, labels\n",
      "\n",
      "    # Apply mapping\n",
      "    dataset = dataset.map(_tf_process, num_parallel_calls=tf.data.AUTOTUNE)\n",
      "\n",
      "    if shuffle:\n",
      "        dataset = dataset.shuffle(1000)\n",
      "\n",
      "    dataset = dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
      "\n",
      "    return dataset\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from src.data.dataloader import make_dataset\n",
    "import inspect\n",
    "\n",
    "print(inspect.getsource(make_dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8b3c4cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images: (32, 48, 48, 3)\n",
      "Age: tf.Tensor([35. 26. 60. 20. 73.], shape=(5,), dtype=float32)\n",
      "Ethnicity: tf.Tensor([0 2 3 0 0], shape=(5,), dtype=int32)\n",
      "Gender: tf.Tensor([0 0 0 1 1], shape=(5,), dtype=int32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-29 06:22:54.408184: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "for images, labels in train_ds.take(1):\n",
    "    print(\"Images:\", images.shape)\n",
    "    print(\"Age:\", labels[\"age\"][:5])\n",
    "    print(\"Ethnicity:\", labels[\"ethnicity\"][:5])\n",
    "    print(\"Gender:\", labels[\"gender\"][:5])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv (3.12.8)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
